{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSIT5800 Introduction to Big Data\n",
    "\n",
    "## Spring 2019\n",
    "\n",
    "## Group Project: Film Recommendation System\n",
    "\n",
    "\n",
    "## Description\n",
    "Blablabla...\n",
    "\n",
    "\n",
    "## Prerequesite\n",
    "\n",
    "You are recommended to install the following packages\n",
    "\n",
    "* pandas\n",
    "* geohash\n",
    "* matplotlib\n",
    "* sklearn\n",
    "\n",
    "\n",
    "## About the data and the context\n",
    "\n",
    "blabla ...\n",
    "## Download Area\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>biketype</th>\n",
       "      <th>starttime</th>\n",
       "      <th>geohashed_start_loc</th>\n",
       "      <th>geohashed_end_loc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orderid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1893973</th>\n",
       "      <td>451147</td>\n",
       "      <td>210617</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-05-14 22:16:50</td>\n",
       "      <td>wx4snhx</td>\n",
       "      <td>wx4snhj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4657992</th>\n",
       "      <td>1061133</td>\n",
       "      <td>465394</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-14 22:16:52</td>\n",
       "      <td>wx4dr59</td>\n",
       "      <td>wx4dquz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2965085</th>\n",
       "      <td>549189</td>\n",
       "      <td>310572</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-14 22:16:51</td>\n",
       "      <td>wx4fgur</td>\n",
       "      <td>wx4fu5n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4548579</th>\n",
       "      <td>489720</td>\n",
       "      <td>456688</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-14 22:16:51</td>\n",
       "      <td>wx4d5r5</td>\n",
       "      <td>wx4d5r4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3936364</th>\n",
       "      <td>467449</td>\n",
       "      <td>403224</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-14 22:16:50</td>\n",
       "      <td>wx4g27p</td>\n",
       "      <td>wx4g266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5163705</th>\n",
       "      <td>917620</td>\n",
       "      <td>509044</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-14 22:16:53</td>\n",
       "      <td>wx4gd2e</td>\n",
       "      <td>wx4g6pw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19818</th>\n",
       "      <td>583391</td>\n",
       "      <td>3190</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-14 22:16:54</td>\n",
       "      <td>wx4fhkk</td>\n",
       "      <td>wx4fh7q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495333</th>\n",
       "      <td>185893</td>\n",
       "      <td>67441</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-14 22:16:53</td>\n",
       "      <td>wx4emgw</td>\n",
       "      <td>wx4emgk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803108</th>\n",
       "      <td>15906</td>\n",
       "      <td>295614</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-05-14 22:16:55</td>\n",
       "      <td>wx4f8t9</td>\n",
       "      <td>wx4f8tj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271970</th>\n",
       "      <td>183740</td>\n",
       "      <td>38335</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-05-14 22:16:54</td>\n",
       "      <td>wx4dzjf</td>\n",
       "      <td>wx4dzhn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          userid  bikeid  biketype            starttime geohashed_start_loc  \\\n",
       "orderid                                                                       \n",
       "1893973   451147  210617         2  2017-05-14 22:16:50             wx4snhx   \n",
       "4657992  1061133  465394         1  2017-05-14 22:16:52             wx4dr59   \n",
       "2965085   549189  310572         1  2017-05-14 22:16:51             wx4fgur   \n",
       "4548579   489720  456688         1  2017-05-14 22:16:51             wx4d5r5   \n",
       "3936364   467449  403224         1  2017-05-14 22:16:50             wx4g27p   \n",
       "5163705   917620  509044         1  2017-05-14 22:16:53             wx4gd2e   \n",
       "19818     583391    3190         1  2017-05-14 22:16:54             wx4fhkk   \n",
       "495333    185893   67441         1  2017-05-14 22:16:53             wx4emgw   \n",
       "2803108    15906  295614         2  2017-05-14 22:16:55             wx4f8t9   \n",
       "271970    183740   38335         1  2017-05-14 22:16:54             wx4dzjf   \n",
       "\n",
       "        geohashed_end_loc  \n",
       "orderid                    \n",
       "1893973           wx4snhj  \n",
       "4657992           wx4dquz  \n",
       "2965085           wx4fu5n  \n",
       "4548579           wx4d5r4  \n",
       "3936364           wx4g266  \n",
       "5163705           wx4g6pw  \n",
       "19818             wx4fh7q  \n",
       "495333            wx4emgk  \n",
       "2803108           wx4f8tj  \n",
       "271970            wx4dzhn  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "mobikedata = pd.read_csv('mobikeData.csv', sep=',', nrows= 10, index_col= ['orderid'])\n",
    "mobikedata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1 - Data Preprocessing and Statistics\n",
    "#\n",
    "#\n",
    "# Task 1.1 Read Mobike Data in using the API Pandas.read_csv so that the column 'starttime' is read as datetime64.\n",
    "#                 Hint: use the parameter parse_dates\n",
    "#                  ref: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
    "#                 To make sure your code works you might want to read only the first 1000 rows and expand it later\n",
    "\n",
    "\n",
    "\n",
    "# Task 1.2 Convert the field geohashed_start_loc and geohashed_end_loc into x-y coordinate using the API Geohash.decode\n",
    "#                  The package Geohash can be found from pip. You might encounter the problem \n",
    "#                   'python3.5.2 can't find the module '  ref: https://github.com/vinsci/geohash/issues/4\n",
    "#                    This can be fixed very easily. Or\n",
    "#                   You might directly use the fixed version of Geohash in our project package.\n",
    "\n",
    "\n",
    "# Task 1.3 Create the column 'distance' based on the Euclidean distance  that the order has traveled.\n",
    "\n",
    "\n",
    "#  Task 1.4.1  Check the memory you have spent by the API .info()\n",
    "\n",
    "#  Task 1.4.2  Compress the field userid bikeid using a smaller data type int32 / uint32 and the field biketype using int8\n",
    "\n",
    "# Task 1.343 Check the memory you have spent again\n",
    "\n",
    "# Task 1.4.4 Fetch the first 10 lines of your data to preview it.\n",
    "\n",
    "\n",
    "# Task 1.5  Display the count, mean, standard derviation of the int type variable and \n",
    "#                  display the earliest and latest starttime.\n",
    "\n",
    "# Task 1.6 Find the number of order between (8am to 9am)   and the order between (1am to 2am)\n",
    "#                 Note: Instead of using only the first 1000 rows, expand your selection of rows to collect enough data.\n",
    "#                Hint: try the API between_time of DataFrame. \n",
    "#           ref:  https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.between_time.html#pandas.DataFrame.between_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2 - Data Clustering \n",
    "#\n",
    "#\n",
    "# Task 2.1 Create a DataFrame that contains two columns. \n",
    "#                 The first column (the index) is a time series 0:00, 0:15, 0:30, 0:45, 1:00,... 23:00, 23:15, 23:30, 23:45\n",
    "#                  The second column is an integer that counts the number of order between in the interval. For example, 0:00 should contains all order happens on or after 0:00 to 0:15.\n",
    "#  This task is less straight forward, at least in our solution. So let's break down a little bit.\n",
    "#  Task 2.1.1 Create a list of string containing the series '0:00', '0:15', '0:30', ... '23:45' \n",
    "#                     Hint: A double loop with if-else can do the job.\n",
    "\n",
    "\n",
    "# Task 2.1.2 Count the number of orders. You might use between_time again.\n",
    "\n",
    "\n",
    "# Task 2.2.1  Use K-mean algorithm to find 300 cluster centers of the coordinates obtained from  Task 1.2\n",
    "#                  You may implement your own K-mean algorithm or simply adopt the API sklearn.cluster.KMeans\n",
    "#                   ref: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "                   \n",
    "\n",
    "\n",
    "    \n",
    "# Task 2.2.2 Describe how many % of order has started from a cluster centers and ends at the same cluster centers.  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3 - Simple Data Visualization \n",
    "#\n",
    "#\n",
    "# Task 3.1 Using data obtained from Task 1.6. Plot a curveof the volume of order in different times of a day.\n",
    "#                    Hint: try the API DataFrame.plot\n",
    "\n",
    "\n",
    "# Task 3.2 Using data obtained from Task 2.2.1. Plot a histogram of the volume of order in different cluster centers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4 - Frequent Pattern Mining \n",
    "#\n",
    "#\n",
    "# Task 4.1 Apply FPGrowth algorithm, either using existing API or write your own, to identify which set of users are likely to go-together. \n",
    "#                 Definition of go-together: they starts at the same cluster centers and their start time is in the same 15-minutes timeslot.\n",
    " #                This task may not be straight forward as you may need to build the list of transaction first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 - Prediction - use bikeshare data\n",
    "\n",
    "You are given a set of training data and 1000 rows of testing data obtained from the same city. The testing data will be 1 days to 7 days after the end of the training data. The fields `to_station_name` and `to_station_id` will be masked with the number -1 in the testing data. Your job is to predict the field `to_station_id`. \n",
    "\n",
    "Write a function that takes two input filenames (the training data and the testing data csv) and output a DataFrame that predict the `to_station_id`. Please note that:\n",
    "* Your function may only predict 1 value for `to_station_id`; \n",
    "* The accurarcy function is defined as `total_numbers_of_match` / `total_number_of_prediction`. \n",
    "* An empty prediction would be counted as one wrong prediction.\n",
    "* You are allowed to use any external data (e.g. weather, map, etc..) for your prediciton. However, this set of data are taken from bikeshare and you are not allowed to lookup the data from the internet.\n",
    "* **A higher accuracy does not immediate imply a higher mark for the project. We value more on how you choose your algorithm and how you fine tune your parameters.**\n",
    "\n",
    "\n",
    "\n",
    "We provide you a reference code (`knn3.py`) written by some Chinese programmer/data scientist that work on the Mobike data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5 Code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Group Presentation\n",
    "\n",
    "Prepare a 5 minutes presentation on your Task 5 prediction work. You will be given another set of training set, testing set of you Task 5 **on 2/5/2019**. Compute the accuracy yourself and include it in your presentation. Your presentation should be focus on why would your choose that particular algorithm and what optimization/fine tuning you have done to improve the accuracy. You can also comment on your accuracy and suggest how could that be improved. \n",
    "\n",
    "You may use the following line to measure the accurarcy\n",
    "```\n",
    "groundtruth['predict'] = output['to_station_id']\n",
    "groundtruth[ groundtruth['predict'] == groundtruth['to_station_id']].count()\n",
    "```\n",
    "\n",
    "Since this is a short presentation, you may assign any member to present the work.\n",
    "\n",
    "**Note: Again, a higher accuracy does not immediate imply a higher mark.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
